Docker & SQL

--1)

docker run -it --rm ubuntu bash   # (adding --rm will automatically remove the container when exits)

$ docker ps -a
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES

$ docker container ls
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES


--2)

docker run -it python:3.9 bash
pip list

root@e2f866310549:/# pip list
Package    Version
---------- -------
pip        23.0.1
setuptools 58.1.0
wheel      0.42.0


--3)

select count(*) from green_taxi_data where lpep_pickup_datetime::date = '2019-09-18'
and lpep_dropoff_datetime::date =  '2019-09-18'; 

=> 15612

--4)

SELECT LPEP_PICKUP_DATETIME :: date
FROM GREEN_TAXI_DATA
WHERE TRIP_DISTANCE = (SELECT MAX(TRIP_DISTANCE) FROM GREEN_TAXI_DATA);

=> 2019-09-26

--5)

select "Borough",sum(fare_amount) as total_amount From green_taxi_data join taxi_zone on "PULocationID" = "LocationID" 
where lpep_pickup_datetime::date = '2019-09-18'
and "Borough" !='Unknown'
group by "Borough" 
having sum(fare_amount) > 50000;

=> "Brooklyn","Manhattan","Queens"

--6)

with pickup_cte as (
select distinct "PULocationID",lpep_pickup_datetime::date as pickup_date,
	lpep_dropoff_datetime::date as dropoff_date,"Zone","DOLocationID",tip_amount from taxi_zone 
	join green_taxi_data on "PULocationID" = "LocationID" 
	where lower("Zone") = 'astoria' and to_char(lpep_pickup_datetime::date,'MM-YYYY') = '09-2019'
	) 
select "Zone" from taxi_zone where "LocationID" =
	(select "DOLocationID" from pickup_cte where tip_amount = 
			(select max(tip_amount) from pickup_cte)
		);

=> JFK Airport


Terraform

terraform apply

Terraform used the selected providers to generate the following execution
plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_bigquery_dataset.dataset will be created
  + resource "google_bigquery_dataset" "dataset" {
      + creation_time              = (known after apply)
      + dataset_id                 = "trips_data_all"
      + delete_contents_on_destroy = false
      + etag                       = (known after apply)
      + id                         = (known after apply)
      + labels                     = (known after apply)
      + last_modified_time         = (known after apply)
      + location                   = "europe-west6"
      + project                    = "composed-sun-375018"
      + self_link                  = (known after apply)

      + access {
          + domain         = (known after apply)
          + group_by_email = (known after apply)
          + role           = (known after apply)
          + special_group  = (known after apply)
          + user_by_email  = (known after apply)

          + dataset {
              + target_types = (known after apply)

              + dataset {
                  + dataset_id = (known after apply)
                  + project_id = (known after apply)
                }
            }

          + routine {
              + dataset_id = (known after apply)
              + project_id = (known after apply)
              + routine_id = (known after apply)
            }

          + view {
              + dataset_id = (known after apply)
              + project_id = (known after apply)
              + table_id   = (known after apply)
            }
        }
    }

  # google_storage_bucket.data-lake-bucket will be created
  + resource "google_storage_bucket" "data-lake-bucket" {
      + force_destroy               = true
      + id                          = (known after apply)
      + location                    = "EUROPE-WEST6"
      + name                        = "dtc_data_lake_composed-sun-375018"
      + project                     = (known after apply)
      + public_access_prevention    = (known after apply)
      + self_link                   = (known after apply)
      + storage_class               = "STANDARD"
      + uniform_bucket_level_access = true
      + url                         = (known after apply)

      + lifecycle_rule {
          + action {
              + type = "Delete"
            }

          + condition {
              + age                   = 30
              + matches_prefix        = []
              + matches_storage_class = []
              + matches_suffix        = []
              + with_state            = (known after apply)
            }
        }

      + versioning {
          + enabled = true
        }

      + website {
          + main_page_suffix = (known after apply)
          + not_found_page   = (known after apply)
        }
    }

Plan: 2 to add, 0 to change, 0 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

google_bigquery_dataset.dataset: Creating...
google_storage_bucket.data-lake-bucket: Creating...
google_storage_bucket.data-lake-bucket: Creation complete after 2s [id=dtc_data_lake_composed-sun-375018]
google_bigquery_dataset.dataset: Creation complete after 3s [id=projects/composed-sun-375018/datasets/trips_data_all]

Apply complete! Resources: 2 added, 0 changed, 0 destroyed.
